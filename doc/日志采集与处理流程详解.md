# 日志采集与处理流程详解

本文档详细说明从 Spring Boot 应用日志输出到 Elasticsearch 存储的完整流程，包括配置、原理和工作机制。

---

## 目录

1. [Spring Boot 日志配置与文件输出](#1-spring-boot-日志配置与文件输出)
2. [日志文件规则与格式](#2-日志文件规则与格式)
3. [Filebeat 日志采集原理与配置](#3-filebeat-日志采集原理与配置)
4. [Filebeat 到 Logstash 数据传输](#4-filebeat-到-logstash-数据传输)
5. [Logstash 日志处理与格式化](#5-logstash-日志处理与格式化)
6. [Elasticsearch 索引配置与数据接收](#6-elasticsearch-索引配置与数据接收)
7. [完整数据流程图](#7-完整数据流程图)

---

## 1. Spring Boot 日志配置与文件输出

### 1.1 日志框架选择

本项目使用 **Logback** 作为日志框架，它是 Spring Boot 默认集成的日志实现。

**Maven 依赖：**
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```
`spring-boot-starter-web` 已经包含了 Logback 的依赖。

### 1.2 日志配置文件

**配置文件位置：** `src/main/resources/logback-spring.xml`

### 1.3 核心配置说明

#### 1.3.1 日志文件路径配置

```xml
<springProperty scope="context" name="LOG_HOME" source="logging.file.path" defaultValue="logs"/>
<property name="LOG_FILE_NAME" value="${LOG_FILE_NAME:-application}"/>
```

**配置说明：**
- `LOG_HOME`：日志文件存储目录
  - 优先级：`application.yaml` 中的 `logging.file.path` > 默认值 `logs`
  - **Docker 环境**：通过挂载映射到 `/var/log/app` 目录
- `LOG_FILE_NAME`：日志文件名称，默认 `application`

**Docker Compose 挂载配置：**
```yaml
volumes:
  - ../logs:/var/log/app:ro  # 挂载项目根目录下的 logs 文件夹
```

#### 1.3.2 日志输出目标

配置了 4 种日志输出方式：

**1. 控制台输出（CONSOLE）**
```xml
<appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
    <encoder>
        <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        <charset>UTF-8</charset>
    </encoder>
</appender>
```

**2. 文件输出 - 所有日志（FILE）**
```xml
<appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>${LOG_HOME}/${LOG_FILE_NAME}.log</file>
    <encoder>
        <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        <charset>UTF-8</charset>
    </encoder>
    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
        <fileNamePattern>${LOG_HOME}/${LOG_FILE_NAME}-%d{yyyy-MM-dd}.log</fileNamePattern>
        <maxHistory>30</maxHistory>
        <totalSizeCap>10GB</totalSizeCap>
    </rollingPolicy>
</appender>
```

**3. 文件输出 - 错误日志（ERROR_FILE）**
```xml
<appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>${LOG_HOME}/${LOG_FILE_NAME}-error.log</file>
    <filter class="ch.qos.logback.classic.filter.LevelFilter">
        <level>ERROR</level>
        <onMatch>ACCEPT</onMatch>
        <onMismatch>DENY</onMismatch>
    </filter>
    <!-- ... -->
</appender>
```

**4. JSON 格式输出（JSON_FILE）**
```xml
<appender name="JSON_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>${LOG_HOME}/${LOG_FILE_NAME}-json.log</file>
    <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
        <providers>
            <timestamp><timeZone>Asia/Shanghai</timeZone></timestamp>
            <version/>
            <logLevel/>
            <loggerName/>
            <message/>
            <mdc/>
            <stackTrace/>
            <pattern>
                <pattern>
                    {
                        "thread": "%thread",
                        "class": "%logger{40}",
                        "method": "%method",
                        "line": "%line"
                    }
                </pattern>
            </pattern>
        </providers>
    </encoder>
    <!-- ... -->
</appender>
```

### 1.4 日志级别配置

```xml
<logger name="org.springframework" level="INFO"/>
<logger name="org.apache" level="INFO"/>
<logger name="org.apache.shardingsphere" level="INFO"/>
<logger name="org.lix.mycatdemo" level="DEBUG"/>

<root level="INFO">
    <appender-ref ref="CONSOLE"/>
    <appender-ref ref="FILE"/>
    <appender-ref ref="ERROR_FILE"/>
    <appender-ref ref="JSON_FILE"/>
</root>
```

---

## 2. 日志文件规则与格式

### 2.1 日志文件命名规则

#### 2.1.1 普通日志文件
- **当前日志文件：** `application.log`
- **历史日志文件：** `application-2026-01-21.log`（按日期滚动）
- **存储位置：** `logs/` 目录（本地开发）或 `/var/log/app/`（Docker 环境）

#### 2.1.2 错误日志文件
- **当前错误日志：** `application-error.log`
- **历史错误日志：** `application-error-2026-01-21.log`
- **保留策略：** 90 天历史，最大 5GB

#### 2.1.3 JSON 格式日志文件
- **当前 JSON 日志：** `application-json.log`
- **历史 JSON 日志：** `application-json-2026-01-21.log`
- **用途：** 便于 Logstash 解析结构化日志

### 2.2 日志文件滚动策略

**滚动策略类型：** `TimeBasedRollingPolicy`（基于时间的滚动策略）

**规则：**
1. **按天滚动：** 每天生成新的日志文件
2. **文件命名：** `{文件名}-{yyyy-MM-dd}.log`
3. **历史保留：** 普通日志保留 30 天，错误日志保留 90 天
4. **总大小限制：** 普通日志最大 10GB，错误日志最大 5GB

**示例：**
```
logs/
├── application.log              # 当前日志（正在写入）
├── application-2026-01-20.log  # 昨天的日志
├── application-2026-01-19.log  # 前天的日志
├── application-error.log        # 当前错误日志
├── application-error-2026-01-20.log
└── application-json.log         # 当前 JSON 日志
```

### 2.3 日志格式说明

#### 2.3.1 普通文本格式

**模式：** `%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n`

**示例输出：**
```
2026-01-21 10:30:45.123 [http-nio-8080-exec-1] INFO  org.lix.mycatdemo.controller.UserController - 用户登录成功
```

**格式说明：**
- `%d{yyyy-MM-dd HH:mm:ss.SSS}`：时间戳（精确到毫秒）
- `[%thread]`：线程名
- `%-5level`：日志级别（左对齐，5 字符宽度）
- `%logger{50}`：Logger 名称（最多 50 字符）
- `%msg`：日志消息
- `%n`：换行符

#### 2.3.2 JSON 格式

**示例输出：**
```json
{
  "@timestamp": "2026-01-21T10:30:45.123+08:00",
  "level": "INFO",
  "logger_name": "org.lix.mycatdemo.controller.UserController",
  "message": "用户登录成功",
  "thread": "http-nio-8080-exec-1",
  "class": "org.lix.mycatdemo.controller.UserController",
  "method": "login",
  "line": 45
}
```

---

## 3. Filebeat 日志采集原理与配置

### 3.1 Filebeat 工作原理

**Filebeat** 是一个轻量级的日志采集工具，基于 Go 语言开发，属于 Elastic Stack 生态的一部分。

#### 3.1.1 核心机制

1. **文件监听（Harvester）：**
   - Filebeat 为每个日志文件启动一个 Harvester（采集器）
   - Harvester 逐行读取文件内容
   - 使用文件偏移量（offset）记录读取位置
   - 支持断点续传，重启后从上次位置继续

2. **状态管理（Registry）：**
   - 将文件读取位置保存在 `registry` 文件中
   - 默认位置：`/usr/share/filebeat/data/registry`
   - 定期刷新状态，确保数据不丢失

3. **事件队列（Spooler）：**
   - 收集的事件先放入内存队列
   - 批量发送到输出目标（Logstash/Elasticsearch）
   - 提高传输效率，减少网络开销

### 3.2 Filebeat 配置详解

**配置文件位置：** `docker/filebeat/filebeat.yml`

#### 3.2.1 输入配置（Inputs）

```yaml
filebeat.inputs:
  # 应用日志输入
  - type: log
    enabled: true
    paths:
      - /var/log/app/*.log
      - /var/log/app/**/*.log
    fields:
      log_type: application
      environment: production
    fields_under_root: false
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after
    exclude_lines: ['^DEBUG']
    
  # Spring Boot 日志输入
  - type: log
    enabled: true
    paths:
      - /var/log/app/spring-boot/*.log
    fields:
      log_type: spring-boot
      environment: production
    fields_under_root: false
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after
```

**配置说明：**

| 配置项 | 说明 |
|--------|------|
| `type: log` | 输入类型为日志文件 |
| `enabled: true` | 启用此输入 |
| `paths` | 日志文件路径，支持通配符和递归匹配 |
| `fields` | 自定义字段，用于标识日志类型 |
| `fields_under_root` | `false` 表示字段放在 `fields` 对象下 |
| `multiline.pattern` | 多行匹配模式（匹配日期开头） |
| `multiline.negate` | `true` 表示不匹配的行 |
| `multiline.match` | `after` 表示追加到上一行 |
| `exclude_lines` | 排除包含指定内容的行 |

**多行日志处理原理：**

Spring Boot 的异常堆栈通常是多行的：
```
2026-01-21 10:30:45.123 [thread] ERROR Logger - 发生异常
java.lang.RuntimeException: 错误信息
    at com.example.Class.method(Class.java:123)
    at com.example.Class.main(Class.java:456)
```

Filebeat 会将这些行合并为一个事件：
- 匹配模式：`^\d{4}-\d{2}-\d{2}`（以日期开头）
- `negate: true`：不匹配日期开头的行（堆栈行）
- `match: after`：将这些行追加到上一行之后

#### 3.2.2 处理器配置（Processors）

```yaml
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
```

**处理器说明：**
- `add_host_metadata`：添加主机信息（主机名、IP 等）
- `add_docker_metadata`：添加 Docker 容器元数据
- `add_kubernetes_metadata`：添加 Kubernetes 元数据（如果适用）

#### 3.2.3 输出配置（Output）

```yaml
output.logstash:
  hosts: ["logstash:5044"]
  loadbalance: true
  compression_level: 3
```

**配置说明：**
- `hosts`：Logstash 地址列表（支持多个，实现高可用）
- `loadbalance: true`：启用负载均衡，轮询发送到多个 Logstash
- `compression_level: 3`：压缩级别（0-9，3 为平衡性能和压缩率）

### 3.3 Filebeat 数据格式

Filebeat 发送到 Logstash 的数据是**结构化事件**，包含以下字段：

```json
{
  "@timestamp": "2026-01-21T10:30:45.123Z",
  "@metadata": {
    "beat": "filebeat",
    "version": "7.17.9"
  },
  "agent": {
    "name": "filebeat",
    "type": "filebeat",
    "version": "7.17.9"
  },
  "host": {
    "name": "hostname",
    "ip": ["192.168.1.100"]
  },
  "fields": {
    "log_type": "application",
    "environment": "production"
  },
  "message": "2026-01-21 10:30:45.123 [thread] INFO Logger - 日志内容",
  "source": "/var/log/app/application.log",
  "offset": 12345,
  "log": {
    "file": {
      "path": "/var/log/app/application.log"
    }
  }
}
```

---

## 4. Filebeat 到 Logstash 数据传输

### 4.1 传输协议

**协议：** Lumberjack Protocol（Beats 协议）

- **端口：** 5044（Logstash Beats 输入默认端口）
- **特性：**
  - 二进制协议，性能优于 JSON over HTTP
  - 支持压缩传输
  - 支持 ACK 确认机制，确保数据不丢失
  - 自动重连和重试

### 4.2 Logstash Beats 输入配置

**配置文件：** `docker/logstash/pipeline/logstash.conf`

```ruby
input {
  beats {
    port => 5044
  }
}
```

**配置说明：**
- `port => 5044`：监听端口 5044
- **Codec：** 默认使用 `beats` codec，自动解析 Beats 协议数据

### 4.3 数据流转过程

1. **Filebeat 收集日志**
   - 读取日志文件
   - 封装为 Beats 事件
   - 压缩数据（`compression_level: 3`）

2. **网络传输**
   - 通过 TCP 连接到 `logstash:5044`
   - 使用 Lumberjack 协议发送数据
   - 等待 ACK 确认

3. **Logstash 接收**
   - 监听 5044 端口
   - 解压数据
   - 解析 Beats 事件结构
   - 将数据传递给 Filter 阶段

### 4.4 高可用与负载均衡

**配置：**
```yaml
output.logstash:
  hosts: ["logstash1:5044", "logstash2:5044"]
  loadbalance: true
```

**工作方式：**
- Filebeat 轮询发送到多个 Logstash 实例
- 如果某个 Logstash 不可用，自动切换到下一个
- 提高系统可用性和吞吐量

---

## 5. Logstash 日志处理与格式化

### 5.1 Logstash 工作原理

Logstash 采用**管道（Pipeline）**架构，包含三个阶段：

```
Input → Filter → Output
```

1. **Input（输入）**：接收数据
2. **Filter（过滤）**：解析、转换、丰富数据
3. **Output（输出）**：发送到目标系统

### 5.2 Filter 阶段详解

#### 5.2.1 条件判断

```ruby
if [fields][log_type] == "application" {
  # 处理应用日志
}
if [fields][log_type] == "spring-boot" {
  # 处理 Spring Boot 日志
}
```

**原理：**
- 根据 Filebeat 添加的 `fields.log_type` 字段区分日志类型
- 不同类型采用不同的解析策略

#### 5.2.2 JSON 日志解析

```ruby
json {
  source => "message"
  target => "parsed"
  skip_on_invalid_json => true
}
```

**处理流程：**
1. 尝试将 `message` 字段解析为 JSON
2. 解析结果存储在 `parsed` 对象中
3. `skip_on_invalid_json => true`：如果解析失败，静默跳过，不报错

**示例：**
- **输入：**
  ```json
  {
    "message": "{\"level\":\"INFO\",\"logger\":\"Logger\",\"message\":\"日志内容\"}"
  }
  ```
- **处理后：**
  ```json
  {
    "message": "...",
    "parsed": {
      "level": "INFO",
      "logger": "Logger",
      "message": "日志内容"
    }
  }
  ```

#### 5.2.3 Grok 模式匹配（Spring Boot 日志）

```ruby
grok {
  match => { 
    "message" => "%{TIMESTAMP_ISO8601:timestamp}%{SPACE}%{LOGLEVEL:log_level}%{SPACE}%{NUMBER:pid}%{SPACE}---%{SPACE}\[%{DATA:thread_name}\]%{SPACE}%{JAVACLASS:logger_name}%{SPACE}:%{SPACE}%{GREEDYDATA:message_content}"
  }
  tag_on_failure => []
}
```

**Grok 原理：**
- Grok 使用正则表达式模式库解析文本
- 匹配模式并提取字段
- `tag_on_failure => []`：匹配失败时不添加标签，避免警告

**模式说明：**
- `%{TIMESTAMP_ISO8601:timestamp}`：匹配 ISO8601 时间戳，存储到 `timestamp` 字段
- `%{LOGLEVEL:log_level}`：匹配日志级别（INFO、ERROR 等）
- `%{DATA:thread_name}`：匹配线程名
- `%{GREEDYDATA:message_content}`：匹配剩余内容

**示例：**
- **输入：**
  ```
  2026-01-21 10:30:45.123 INFO 12345 --- [http-nio-8080-exec-1] o.l.m.controller.UserController : 用户登录成功
  ```
- **提取结果：**
  ```json
  {
    "timestamp": "2026-01-21 10:30:45.123",
    "log_level": "INFO",
    "thread_name": "http-nio-8080-exec-1",
    "logger_name": "o.l.m.controller.UserController",
    "message_content": "用户登录成功"
  }
  ```

#### 5.2.4 时间戳解析

```ruby
date {
  match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
  target => "@timestamp"
}
```

**原理：**
- 将解析出的时间戳字符串转换为 Elasticsearch 标准的 `@timestamp` 字段
- ES 使用 `@timestamp` 作为文档的时间字段，用于时间序列查询

#### 5.2.5 字段操作（Mutate）

```ruby
mutate {
  add_field => { 
    "log_level" => "%{[parsed][level]}"
    "logger_name" => "%{[parsed][logger]}"
  }
}
```

**操作类型：**
- `add_field`：添加字段
- `remove_field`：删除字段
- `rename`：重命名字段
- `convert`：转换字段类型

#### 5.2.6 标签添加

```ruby
if [log_level] == "ERROR" {
  mutate {
    add_tag => [ "error" ]
  }
}
```

**用途：**
- 为特定类型的日志添加标签
- 便于在 Kibana 中过滤和搜索

### 5.3 Output 阶段详解

```ruby
output {
  elasticsearch {
    hosts => ["http://es-node1:9200", "http://es-node2:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    template_name => "logs"
    template => "/usr/share/logstash/templates/logs-template.json"
    template_overwrite => true
  }
}
```

**配置说明：**

| 配置项 | 说明 |
|--------|------|
| `hosts` | ES 集群节点地址列表 |
| `index` | 索引名称模式，使用日期动态生成 |
| `template_name` | 索引模板名称 |
| `template` | 模板文件路径 |
| `template_overwrite` | 允许覆盖已存在的模板 |

**索引命名规则：**
- `logs-%{+YYYY.MM.dd}` 动态生成索引名
- 示例：`logs-2026.01.21`、`logs-2026.01.22`
- **优势：** 按日期分索引，便于数据管理和清理

**数据传输：**
- 使用 HTTP REST API 发送数据到 ES
- 批量写入（bulk API），提高性能
- 自动重试失败的请求

---

## 6. Elasticsearch 索引配置与数据接收

### 6.1 索引模板（Index Template）

**模板文件：** `docker/logstash/templates/logs-template.json`

```json
{
  "index_patterns": ["logs-*"],
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1,
    "index.refresh_interval": "5s",
    "index.codec": "best_compression"
  },
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" },
      "message": {
        "type": "text",
        "fields": {
          "keyword": { "type": "keyword", "ignore_above": 256 }
        }
      },
      "log_level": { "type": "keyword" },
      "logger_name": { "type": "keyword" },
      "host": {
        "properties": {
          "name": { "type": "keyword" },
          "ip": { "type": "ip" }
        }
      }
    }
  }
}
```

#### 6.1.1 模板匹配规则

- `index_patterns: ["logs-*"]`：匹配所有以 `logs-` 开头的索引
- 当创建新索引（如 `logs-2026.01.21`）时，自动应用此模板

#### 6.1.2 索引设置（Settings）

| 配置项 | 说明 |
|--------|------|
| `number_of_shards` | 主分片数量（1 个） |
| `number_of_replicas` | 副本数量（1 个，确保高可用） |
| `index.refresh_interval` | 刷新间隔（5 秒，控制搜索可见延迟） |
| `index.codec` | 压缩算法（best_compression，节省存储） |

#### 6.1.3 字段映射（Mappings）

**字段类型说明：**

1. **@timestamp（date）**
   - ES 标准时间字段
   - 用于时间范围查询和排序

2. **message（text + keyword）**
   - `text`：全文搜索，支持分词
   - `message.keyword`：精确匹配，用于聚合和排序

3. **log_level、logger_name（keyword）**
   - 不分词，精确匹配
   - 适合过滤和聚合操作

4. **host.ip（ip）**
   - IP 地址类型
   - 支持 IP 范围查询

### 6.2 索引自动创建

**工作原理：**

1. Logstash 发送文档到 ES
2. ES 检查索引是否存在
3. 如果不存在，根据索引名匹配模板
4. 应用模板创建索引
5. 写入文档

**触发条件：**
- Logstash 配置中的 `index => "logs-%{+YYYY.MM.dd}"` 会每天自动创建新索引
- 首次写入时，ES 根据模板自动创建索引结构

### 6.3 数据接收与存储

#### 6.3.1 Bulk API

Logstash 使用 **Bulk API** 批量写入数据：

```json
POST /_bulk
{"index":{"_index":"logs-2026.01.21"}}
{"@timestamp":"2026-01-21T10:30:45.123Z","message":"日志内容",...}
{"index":{"_index":"logs-2026.01.21"}}
{"@timestamp":"2026-01-21T10:30:46.456Z","message":"日志内容",...}
```

**优势：**
- 批量操作，减少网络往返
- 提高写入性能

#### 6.3.2 文档结构

**最终存储在 ES 中的文档示例：**

```json
{
  "_index": "logs-2026.01.21",
  "_type": "_doc",
  "_id": "auto-generated-id",
  "_source": {
    "@timestamp": "2026-01-21T10:30:45.123Z",
    "message": "2026-01-21 10:30:45.123 [thread] INFO Logger - 日志内容",
    "message_content": "日志内容",
    "log_level": "INFO",
    "logger_name": "org.lix.mycatdemo.Logger",
    "thread_name": "http-nio-8080-exec-1",
    "host": {
      "name": "container-name",
      "ip": ["172.18.0.5"]
    },
    "host_name": "container-name",
    "host_ip": "172.18.0.5",
    "fields": {
      "log_type": "application",
      "environment": "production"
    },
    "tags": ["error"]
  }
}
```

---

## 7. 完整数据流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                     Spring Boot 应用                              │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Logback 日志框架                                         │   │
│  │  - 接收日志事件（slf4j API）                              │   │
│  │  - 格式化日志（Pattern/JSON）                             │   │
│  │  - 输出到多个 Appender                                    │   │
│  └──────────────────────────────────────────────────────────┘   │
│                         │                                         │
│         ┌───────────────┼───────────────┐                        │
│         │               │               │                        │
│    ┌────▼────┐    ┌─────▼─────┐   ┌────▼────┐                   │
│    │ CONSOLE │    │   FILE    │   │JSON_FILE│                   │
│    │ 控制台   │    │ 文件输出   │   │JSON输出 │                   │
│    └─────────┘    └───────────┘   └─────────┘                   │
└─────────────────────────────────────────────────────────────────┘
                          │
                          │ 写入日志文件
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                   日志文件系统                                     │
│  /var/log/app/                                                    │
│  ├── application.log                                              │
│  ├── application-error.log                                        │
│  └── application-json.log                                         │
└─────────────────────────────────────────────────────────────────┘
                          │
                          │ Filebeat 监听并读取
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Filebeat                                     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Harvester（采集器）                                      │   │
│  │  - 监听文件变化                                           │   │
│  │  - 逐行读取                                               │   │
│  │  - 记录偏移量（Registry）                                 │   │
│  └──────────────────────────────────────────────────────────┘   │
│                          │                                        │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Processors（处理器）                                     │   │
│  │  - 添加主机元数据                                         │   │
│  │  - 添加 Docker 元数据                                     │   │
│  │  - 多行日志合并                                           │   │
│  └──────────────────────────────────────────────────────────┘   │
│                          │                                        │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Output（输出）                                           │   │
│  │  - 封装为 Beats 事件                                      │   │
│  │  - 压缩数据                                               │   │
│  │  - 通过 Lumberjack 协议发送                               │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
                          │
                          │ TCP 5044 端口
                          │ Lumberjack 协议
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Logstash                                     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Input: Beats Plugin                                     │   │
│  │  - 监听 5044 端口                                        │   │
│  │  - 接收 Beats 事件                                       │   │
│  │  - 解析事件结构                                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                          │                                        │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Filter: 数据处理                                        │   │
│  │  - 根据 log_type 判断日志类型                            │   │
│  │  - JSON 解析 / Grok 模式匹配                             │   │
│  │  - 时间戳解析                                            │   │
│  │  - 字段提取和转换                                        │   │
│  │  - 添加标签                                              │   │
│  └──────────────────────────────────────────────────────────┘   │
│                          │                                        │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  Output: Elasticsearch Plugin                            │   │
│  │  - 批量写入（Bulk API）                                   │   │
│  │  - 动态索引名（logs-YYYY.MM.dd）                          │   │
│  │  - 应用索引模板                                          │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
                          │
                          │ HTTP REST API
                          │ Bulk API
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                  Elasticsearch 集群                               │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  索引管理                                                 │   │
│  │  - 匹配模板（logs-*）                                    │   │
│  │  - 自动创建索引（首次写入）                               │   │
│  │  - 应用字段映射和设置                                    │   │
│  └──────────────────────────────────────────────────────────┘   │
│                          │                                        │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  文档存储                                                 │   │
│  │  - 分片存储（Sharding）                                   │   │
│  │  - 副本复制（Replication）                                │   │
│  │  - 索引和搜索                                            │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
                          │
                          │ 查询接口
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Kibana                                       │
│  - 可视化查询和展示                                              │
│  - 创建仪表板和图表                                              │
│  - 日志分析和监控                                                │
└─────────────────────────────────────────────────────────────────┘
```

---

## 8. 关键配置总结

### 8.1 Spring Boot 日志配置

**文件：** `logback-spring.xml`
- 日志路径：`logs/` 或 `/var/log/app/`
- 文件滚动：按天滚动，保留 30 天
- 输出格式：文本格式 + JSON 格式

### 8.2 Filebeat 配置

**文件：** `docker/filebeat/filebeat.yml`
- 监听路径：`/var/log/app/*.log`
- 输出目标：`logstash:5044`
- 压缩传输：`compression_level: 3`

### 8.3 Logstash 配置

**文件：** `docker/logstash/pipeline/logstash.conf`
- 输入端口：`5044`（Beats）
- 索引模式：`logs-%{+YYYY.MM.dd}`
- 模板文件：`/usr/share/logstash/templates/logs-template.json`

### 8.4 Elasticsearch 配置

**模板：** `logs-template.json`
- 索引模式：`logs-*`
- 分片数：1
- 副本数：1

---

## 9. 故障排查

### 9.1 日志文件未生成

**检查项：**
1. 确认 `logging.file.path` 配置正确
2. 检查目录权限
3. 查看 Logback 配置是否有语法错误

### 9.2 Filebeat 未采集日志

**检查项：**
1. 确认日志文件路径匹配 `paths` 配置
2. 检查 Filebeat 日志：`docker logs filebeat`
3. 确认 Registry 文件存在且可读

### 9.3 Logstash 未接收数据

**检查项：**
1. 确认 Logstash 监听端口：`netstat -tuln | grep 5044`
2. 检查网络连通性：`docker exec filebeat ping logstash`
3. 查看 Logstash 日志：`docker logs logstash`

### 9.4 ES 索引未创建

**检查项：**
1. 确认模板文件路径正确
2. 检查 ES 集群健康状态
3. 查看 Logstash 输出日志中的错误信息

---

## 10. 性能优化建议

1. **日志文件大小**：合理设置滚动策略，避免单个文件过大
2. **Filebeat 批量大小**：调整 `bulk_max_size` 参数
3. **Logstash 工作线程**：根据 CPU 核心数调整 `pipeline.workers`
4. **ES 索引设置**：根据数据量调整分片数和副本数
5. **压缩传输**：启用 Filebeat 压缩，减少网络带宽

---

**文档版本：** 1.0  
**最后更新：** 2026-01-21  
**维护者：** 开发团队

